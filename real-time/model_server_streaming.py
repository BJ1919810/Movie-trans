#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import json
import traceback
import librosa
import soundfile as sf
import torch
from flask import Flask, request, jsonify, Response, stream_with_context
from pathlib import Path
import logging
import io
import base64
import numpy as np
import tempfile

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
localdir_path = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_path)
sys.path.append(localdir_path)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from uvr5.vr import AudioPre
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥uvr5æ¨¡å—")
    AudioPre = None

try:
    from faster_whisper import WhisperModel
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥faster_whisperæ¨¡å—")
    WhisperModel = None

try:
    from funasr import AutoModel
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥funasræ¨¡å—")
    AutoModel = None

import requests

# é…ç½®å‚æ•°
TEMP_DIR = os.path.join(project_path, "temp")
RESULTS_DIR = os.path.join(project_path, "results")
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

# UVR5é…ç½®
weight_uvr5_root = os.path.join(project_path, "uvr5", "uvr5_weights")
device = "cuda" if torch.cuda.is_available() else "cpu"
is_half = False
model_name = "HP2_all_vocals"  # hp2æ¨¡å‹ç”¨äºä¿ç•™äººå£°
agg = 10  # äººå£°æå–æ¿€è¿›ç¨‹åº¦
format0 = "wav"  # å¯¼å‡ºæ–‡ä»¶æ ¼å¼

# ASRæ¨¡å‹è·¯å¾„é…ç½®
asr_models_path = os.path.join(project_path, "asr", "models")
whisper_model_path = os.path.join(asr_models_path, "models--Systran--faster-whisper-large-v3")
funasr_asr_model_path = os.path.join(asr_models_path, "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
funasr_vad_model_path = os.path.join(asr_models_path, "speech_fsmn_vad_zh-cn-16k-common-pytorch")
funasr_punc_model_path = os.path.join(asr_models_path, "punc_ct-transformer_zh-cn-common-vocab272727-pytorch")

# TTSæ¨¡å‹è·¯å¾„é…ç½®
tts_checkpoint_path = os.path.join(project_path, "checkpoints")
default_ref_audio_path = os.path.join(project_path, "default_ref_voice.wav")  # é»˜è®¤å‚è€ƒéŸ³é¢‘

# DeepSeek APIé…ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥ï¼‰
DEEPSEEK_API_KEY = "your-deepseek-api-key"
DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨é¢„åŠ è½½çš„æ¨¡å‹
preloaded_models = {}

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)

def check_model_files(model_path, required_files=None):
    """
    æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´
    """
    if not os.path.exists(model_path):
        logger.warning(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    if required_files:
        for file in required_files:
            if not os.path.exists(os.path.join(model_path, file)):
                logger.warning(f"æ¨¡å‹æ–‡ä»¶ç¼ºå¤±: {os.path.join(model_path, file)}")
                return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
    model_files = [f for f in os.listdir(model_path) if f.endswith(('.pt', '.bin', '.pth', '.safetensors'))]
    if not model_files:
        logger.warning(f"æ¨¡å‹è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        return False
        
    logger.info(f"æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡: {model_path}")
    return True

def preload_models():
    """
    é¢„åŠ è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹
    """
    global preloaded_models
    
    try:
        logger.info("å¼€å§‹é¢„åŠ è½½æ¨¡å‹...")
        
        # 1. é¢„åŠ è½½UVR5æ¨¡å‹
        logger.info("é¢„åŠ è½½UVR5æ¨¡å‹...")
        uvr5_model_path = os.path.join(weight_uvr5_root, model_name + ".pth")
        if os.path.exists(uvr5_model_path) and AudioPre:
            preloaded_models['uvr5'] = AudioPre(
                agg=int(agg),
                model_path=uvr5_model_path,
                device=device,
                is_half=is_half,
            )
            logger.info("UVR5æ¨¡å‹é¢„åŠ è½½å®Œæˆ")
        else:
            logger.error(f"UVR5æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {uvr5_model_path}")
            preloaded_models['uvr5'] = None
        
        # 2. é¢„åŠ è½½FunASRæ¨¡å‹ï¼ˆä¸­æ–‡ï¼‰
        logger.info("é¢„åŠ è½½FunASRä¸­æ–‡æ¨¡å‹...")
        if (AutoModel and
            os.path.exists(funasr_asr_model_path) and 
            os.path.exists(funasr_vad_model_path) and 
            os.path.exists(funasr_punc_model_path) and
            check_model_files(funasr_asr_model_path, ['model.pt']) and
            check_model_files(funasr_vad_model_path, ['model.pt']) and
            check_model_files(funasr_punc_model_path, ['model.pt'])):
            
            logger.info("ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„åŠ è½½FunASR...")
            preloaded_models['funasr_zh'] = AutoModel(
                model=funasr_asr_model_path,
                vad_model=funasr_vad_model_path,
                punc_model=funasr_punc_model_path,
            )
            logger.info("FunASRä¸­æ–‡æ¨¡å‹é¢„åŠ è½½å®Œæˆ")
        else:
            logger.warning("æœ¬åœ°FunASRæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œè·³è¿‡åŠ è½½")
            preloaded_models['funasr_zh'] = None
            
        # 3. é¢„åŠ è½½Faster-Whisperæ¨¡å‹ï¼ˆå¤šè¯­è¨€ï¼‰
        logger.info("é¢„åŠ è½½Faster-Whisperå¤šè¯­è¨€æ¨¡å‹...")
        # æŸ¥æ‰¾whisperæ¨¡å‹çš„å®é™…è·¯å¾„
        whisper_actual_path = None
        if os.path.exists(whisper_model_path):
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿«ç…§ç›®å½•
            snapshots_path = os.path.join(whisper_model_path, "snapshots")
            if os.path.exists(snapshots_path):
                # è·å–æœ€æ–°çš„å¿«ç…§ç›®å½•
                snapshots = [d for d in os.listdir(snapshots_path) if os.path.isdir(os.path.join(snapshots_path, d))]
                if snapshots:
                    whisper_actual_path = os.path.join(snapshots_path, snapshots[0])
                    logger.info(f"æ‰¾åˆ°Whisperæ¨¡å‹å¿«ç…§è·¯å¾„: {whisper_actual_path}")
                else:
                    logger.warning("Whisperæ¨¡å‹å¿«ç…§ç›®å½•ä¸ºç©º")
            else:
                # ç›´æ¥ä½¿ç”¨æ¨¡å‹ç›®å½•
                whisper_actual_path = whisper_model_path
                logger.info(f"ä½¿ç”¨Whisperæ¨¡å‹ç›®å½•: {whisper_actual_path}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if WhisperModel and whisper_actual_path and check_model_files(whisper_actual_path):
            try:
                logger.info("ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹è·¯å¾„åŠ è½½...")
                preloaded_models['whisper'] = WhisperModel(
                    whisper_actual_path, 
                    device=device, 
                    compute_type="float16" if is_half and device=="cuda" else "float32"
                )
                logger.info("Faster-Whisperå¤šè¯­è¨€æ¨¡å‹é¢„åŠ è½½å®Œæˆ")
            except Exception as e:
                logger.error(f"åŠ è½½Whisperæ¨¡å‹å¤±è´¥: {e}")
                preloaded_models['whisper'] = None
        else:
            logger.warning("æœ¬åœ°Whisperæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œè·³è¿‡åŠ è½½")
            preloaded_models['whisper'] = None
            
        # 4. åˆå§‹åŒ–IndexTTSæ¨¡å‹
        logger.info("åˆå§‹åŒ–IndexTTSæ¨¡å‹...")
        sys.path.append(os.path.join(project_path, 'index-tts'))
        
        # æ£€æŸ¥TTSæ¨¡å‹è·¯å¾„
        tts_config_path = os.path.join(project_path, "index-tts", "checkpoints", "config.yaml")
        tts_model_dir = os.path.join(project_path, "index-tts", "checkpoints")
        
        if os.path.exists(tts_config_path) and os.path.exists(tts_model_dir):
            try:
                from indextts.infer_v2 import IndexTTS2
                preloaded_models['tts'] = IndexTTS2(
                    cfg_path=tts_config_path,
                    model_dir=tts_model_dir,
                    use_fp16=True
                )
                logger.info("IndexTTSæ¨¡å‹åˆå§‹åŒ–å®Œæˆ(å·²å¯ç”¨DeepSpeedä¼˜åŒ–)")
            except Exception as e:
                logger.error(f"åŠ è½½IndexTTSæ¨¡å‹å¤±è´¥: {e}")
                preloaded_models['tts'] = None
        else:
            logger.warning("TTSæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡TTSæ¨¡å‹åŠ è½½")
            preloaded_models['tts'] = None
            
        # 5. æ£€æŸ¥é»˜è®¤å‚è€ƒéŸ³é¢‘
        if not os.path.exists(default_ref_audio_path):
            logger.warning(f"é»˜è®¤å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {default_ref_audio_path}")
            # å°è¯•åˆ›å»ºä¸€ä¸ªç©ºçš„å‚è€ƒéŸ³é¢‘
            try:
                sr = 16000
                y = np.zeros(sr)  # 1ç§’é™éŸ³
                sf.write(default_ref_audio_path, y, sr, subtype='PCM_16')
                logger.info("å·²åˆ›å»ºé»˜è®¤å‚è€ƒéŸ³é¢‘(é™éŸ³)")
            except Exception as e:
                logger.error(f"åˆ›å»ºé»˜è®¤å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
            
        logger.info("æ‰€æœ‰æ¨¡å‹é¢„åŠ è½½å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def denoise_audio_hp2(input_audio_path):
    """
    ä½¿ç”¨HP2æ¨¡å‹å¯¹éŸ³é¢‘è¿›è¡Œé™å™ªï¼Œåªä¿ç•™äººå£°
    æµç¨‹è°ƒæ•´ï¼š
    1. ä¿ç•™åŸå§‹åŒå£°é“è¾“å…¥
    2. UVR5å¤„ç†åŒå£°é“éŸ³é¢‘
    3. ä»UVR5è¾“å‡ºä¸­æå–å³å£°é“
    4. ç”Ÿæˆ16kHzå•å£°é“å¤„ç†éŸ³é¢‘
    5. ç”Ÿæˆ16kHzå•å£°é“å‚è€ƒéŸ³é¢‘ï¼ˆå®Œå…¨ç§»é™¤44ké€»è¾‘ï¼‰
    
    è¿”å›: (16kHzå•å£°é“å¤„ç†éŸ³é¢‘, 16kHzå•å£°é“å‚è€ƒéŸ³é¢‘)
    """
    try:
        logger.info(f"ğŸ”Š ä½¿ç”¨HP2æ¨¡å‹å¤„ç†éŸ³é¢‘: {input_audio_path}")
        
        # æ£€æŸ¥UVR5æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if preloaded_models['uvr5'] is None:
            logger.error("UVR5æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé™å™ªå¤„ç†")
            return None, None
        
        # 1ï¸âƒ£ ä¿ç•™åŸå§‹åŒå£°é“è¾“å…¥ï¼ˆä¸å†æå‰å¤„ç†ï¼‰
        logger.info("ğŸ¯ ä¿ç•™åŸå§‹åŒå£°é“è¾“å…¥ï¼Œç›´æ¥é€å…¥UVR5å¤„ç†...")
        
        # 2ï¸âƒ£ ä½¿ç”¨é¢„åŠ è½½çš„æ¨¡å‹å¤„ç†åŸå§‹éŸ³é¢‘
        pre_fun = preloaded_models['uvr5']
        output_vocal_path = TEMP_DIR
        output_ins_path = TEMP_DIR
        
        logger.info("ğŸ”„ UVR5æ¨¡å‹å¤„ç†ä¸­ï¼ˆä¿ç•™åŸå§‹åŒå£°é“ï¼‰...")
        pre_fun._path_audio_(input_audio_path, output_ins_path, output_vocal_path, format0)
        logger.info("âœ… UVR5å¤„ç†å®Œæˆ")
            
        # 3ï¸âƒ£ è·å–UVR5è¾“å‡ºçš„äººå£°æ–‡ä»¶
        vocal_filename = f"vocal_{os.path.basename(input_audio_path)}_{agg}.{format0}"
        vocal_file = os.path.join(output_vocal_path, vocal_filename)
        
        if not os.path.exists(vocal_file):
            logger.error(f"âŒ æœªæ‰¾åˆ°UVR5å¤„ç†åçš„äººå£°æ–‡ä»¶: {vocal_file}")
            return None, None
        
        logger.info(f"ğŸ” æ‰¾åˆ°UVR5è¾“å‡ºæ–‡ä»¶: {vocal_file}")
        
        # 4ï¸âƒ£ ä»UVR5è¾“å‡ºä¸­æå–å³å£°é“
        logger.info("ğŸ¤ ä»UVR5è¾“å‡ºä¸­æå–å³å£°é“...")
        y, sr = librosa.load(vocal_file, sr=None, mono=False)
        
        # æ·»åŠ éŸ³é¢‘æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
        if not np.all(np.isfinite(y)):
            logger.warning("âš ï¸ æ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®ä¸­å­˜åœ¨éæœ‰é™å€¼ï¼Œæ­£åœ¨è¿›è¡Œæ¸…ç†...")
            y = np.nan_to_num(y, nan=0.0, posinf=0.95, neginf=-0.95)
        
        if y.ndim > 1:
            logger.info(f"ğŸ§ æ£€æµ‹åˆ°ç«‹ä½“å£°éŸ³é¢‘ï¼ˆ{sr}Hzï¼‰ï¼Œæå–å³å£°é“...")
            right_channel = y[1]  # å³å£°é“æ˜¯ç´¢å¼•1
        else:
            logger.info("_mono æ£€æµ‹åˆ°å•å£°é“éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨...")
            right_channel = y
            
        # å†æ¬¡æ£€æŸ¥æå–åçš„éŸ³é¢‘æ•°æ®
        if not np.all(np.isfinite(right_channel)):
            logger.warning("âš ï¸ å³å£°é“éŸ³é¢‘æ•°æ®ä¸­å­˜åœ¨éæœ‰é™å€¼ï¼Œæ­£åœ¨è¿›è¡Œæ¸…ç†...")
            right_channel = np.nan_to_num(right_channel, nan=0.0, posinf=0.95, neginf=-0.95)
        
        # 5ï¸âƒ£ ç”Ÿæˆ16kHzå•å£°é“å¤„ç†éŸ³é¢‘ï¼ˆç”¨äºASRï¼‰
        logger.info("ğŸ”„ é‡é‡‡æ ·åˆ°16000Hzï¼ˆç”¨äºASRï¼‰...")
        vocal_processed_16k = librosa.resample(right_channel, orig_sr=sr, target_sr=16000)
        
        # æ£€æŸ¥é‡é‡‡æ ·åçš„éŸ³é¢‘æ•°æ®
        if not np.all(np.isfinite(vocal_processed_16k)):
            logger.warning("âš ï¸ é‡é‡‡æ ·åçš„ASRéŸ³é¢‘æ•°æ®ä¸­å­˜åœ¨éæœ‰é™å€¼ï¼Œæ­£åœ¨è¿›è¡Œæ¸…ç†...")
            vocal_processed_16k = np.nan_to_num(vocal_processed_16k, nan=0.0, posinf=0.95, neginf=-0.95)
            
        vocal_16k_path = os.path.join(output_vocal_path, "vocal_processed_16k.wav")
        sf.write(vocal_16k_path, vocal_processed_16k, 16000, subtype='PCM_16')
        
        # 6ï¸âƒ£ ç”Ÿæˆ16kHzå•å£°é“å‚è€ƒéŸ³é¢‘ï¼ˆç”¨äºTTSï¼Œä¿æŒéŸ³è‰²ï¼‰
        logger.info("ğŸ”„ ç”Ÿæˆ16kHzå‚è€ƒéŸ³é¢‘ï¼ˆç”¨äºTTSéŸ³è‰²ä¿æŒï¼‰...")
        ref_audio_16k = librosa.resample(right_channel, orig_sr=sr, target_sr=16000)
        
        # æ£€æŸ¥é‡é‡‡æ ·åçš„å‚è€ƒéŸ³é¢‘æ•°æ®
        if not np.all(np.isfinite(ref_audio_16k)):
            logger.warning("âš ï¸ é‡é‡‡æ ·åçš„TTSå‚è€ƒéŸ³é¢‘æ•°æ®ä¸­å­˜åœ¨éæœ‰é™å€¼ï¼Œæ­£åœ¨è¿›è¡Œæ¸…ç†...")
            ref_audio_16k = np.nan_to_num(ref_audio_16k, nan=0.0, posinf=0.95, neginf=-0.95)
        
        # ğŸ›¡ï¸ ä¼˜åŒ–TTSå‚è€ƒéŸ³é¢‘ï¼šå¢å¼ºè¯­éŸ³è´¨é‡
        ref_audio_16k = np.clip(ref_audio_16k, -0.95, 0.95)  # é™åˆ¶å¹…åº¦
        ref_audio_16k_path = os.path.join(output_vocal_path, "vocal_ref_16k.wav")
        sf.write(ref_audio_16k_path, ref_audio_16k, 16000, subtype='PCM_24')
        
        logger.info(f"âœ… éŸ³é¢‘å¤„ç†å®Œæˆï¼")
        logger.info(f"   ğŸ“Š ASRç”¨éŸ³é¢‘: {vocal_16k_path}")
        logger.info(f"   ğŸµ TTSç”¨å‚è€ƒ: {ref_audio_16k_path}")
        
        return vocal_16k_path, ref_audio_16k_path  # âœ… ä¸¤ä¸ªéƒ½æ˜¯16kHzå•å£°é“
            
    except Exception as e:
        logger.error(f"ğŸ’” HP2é™å™ªå¤„ç†é”™è¯¯: {e}")
        traceback.print_exc()
        return None, None

def asr_recognition(audio_file, language=None):
    """
    æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„ASRæ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
    """
    try:
        logger.info(f"ğŸ—£ï¸ å¼€å§‹ASRè¯†åˆ«ï¼Œè¯­è¨€: {language}")
        
        # å¦‚æœæŒ‡å®šäº†ä¸­æ–‡æˆ–è‡ªåŠ¨æ£€æµ‹ä¸ºä¸­æ–‡ï¼Œä½¿ç”¨FunASR
        if language == "zh" or (language == "auto" and preloaded_models['funasr_zh']):
            logger.info("ä½¿ç”¨FunASRè¿›è¡Œä¸­æ–‡è¯†åˆ«...")
            return asr_with_funasr(audio_file)
        # å¯¹äºå…¶ä»–è¯­è¨€ï¼Œä½¿ç”¨Faster-Whisper
        elif preloaded_models['whisper']:
            logger.info("ä½¿ç”¨Faster-Whisperè¿›è¡Œå¤šè¯­è¨€è¯†åˆ«...")
            return asr_with_whisper(audio_file, language)
        # Fallbackåˆ°FunASR
        elif preloaded_models['funasr_zh']:
            logger.info("Fallbackåˆ°FunASRè¿›è¡Œè¯†åˆ«...")
            return asr_with_funasr(audio_file)
        else:
            logger.error("æ²¡æœ‰å¯ç”¨çš„ASRæ¨¡å‹")
            return ""
            
    except Exception as e:
        logger.error(f"ASRè¯†åˆ«è¿‡ç¨‹é”™è¯¯: {e}")
        traceback.print_exc()
        return ""

def asr_with_funasr(audio_file):
    """
    ä½¿ç”¨é¢„åŠ è½½çš„FunASRè¿›è¡Œä¸­æ–‡è¯­éŸ³è¯†åˆ«
    """
    try:
        logger.info("ä½¿ç”¨FunASRè¿›è¡Œä¸­æ–‡ASR...")
        model = preloaded_models['funasr_zh']
        result = model.generate(input=audio_file)
        return result[0]["text"] if result else ""
    except Exception as e:
        logger.error(f"FunASRè¯†åˆ«é”™è¯¯: {e}")
        traceback.print_exc()
        return ""

def asr_with_whisper(audio_file, language=None):
    """
    ä½¿ç”¨é¢„åŠ è½½çš„Faster-Whisperè¿›è¡Œå¤šè¯­è¨€è¯­éŸ³è¯†åˆ«
    """
    try:
        logger.info("ä½¿ç”¨Faster-Whisperè¿›è¡Œå¤šè¯­è¨€ASR...")
        model = preloaded_models['whisper']
        
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        y, sr = librosa.load(audio_file, sr=None)
        
        # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯16000ï¼Œéœ€è¦é‡æ–°é‡‡æ ·
        if sr != 16000:
            y = librosa.resample(y, orig_sr=sr, target_sr=16000)
        
        # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•
        segments, info = model.transcribe(
            audio_file, 
            beam_size=5,
            language=language if language != "auto" else None,
            condition_on_previous_text=True
        )
        
        # åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
        text = "".join([segment.text for segment in segments])
        logger.info(f"Whisperè¯†åˆ«ç»“æœ: {text}")
        return text
    except Exception as e:
        logger.error(f"Faster-Whisperè¯†åˆ«é”™è¯¯: {e}")
        traceback.print_exc()
        return ""

def translate_text(text, target_language="zh", source_language="en"):
    """
    ç¿»è¯‘æ–‡æœ¬åˆ°ç›®æ ‡è¯­è¨€
    """
    try:
        logger.info(f"ğŸŒ ç¿»è¯‘æ–‡æœ¬ä» {source_language} åˆ° {target_language}")
        
        # æ„é€ è¯­è¨€æ˜ å°„
        language_map = {
            "zh": "ä¸­æ–‡",
            "en": "è‹±æ–‡",
            "ja": "æ—¥æ–‡"
        }
        display_target = language_map.get(target_language, "ä¸­æ–‡")
        display_source = language_map.get(source_language, "è‹±æ–‡")
        
        # æ„é€ æç¤ºè¯
        if source_language == "zh" and target_language == "en":
            system_prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘äººå‘˜ï¼Œè¯·å°†ä»¥ä¸‹{display_source}çš„å¯¹è¯å†…å®¹ç›´æ¥ç¿»è¯‘æˆ{display_target}ï¼Œä¿æŒå¯¹è¯çš„è‡ªç„¶æµç•…æ€§ã€‚"
        elif source_language == "en" and target_language == "zh":
            system_prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘äººå‘˜ï¼Œè¯·å°†ä»¥ä¸‹{display_source}çš„å¯¹è¯å†…å®¹ç¿»è¯‘æˆ{display_target}ï¼Œä¿æŒå¯¹è¯çš„è‡ªç„¶æµç•…æ€§ã€‚"
        else:
            system_prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘äººå‘˜ï¼Œè¯·å°†ä»¥ä¸‹{display_source}çš„å¯¹è¯å†…å®¹ç¿»è¯‘æˆ{display_target}ï¼Œä¿æŒå¯¹è¯çš„è‡ªç„¶æµç•…æ€§ã€‚"
        
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{text}"
                }
            ],
            "stream": False
        }
        
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        result = response.json()
        translated_text = result['choices'][0]['message']['content'].strip()
        logger.info(f"âœ… ç¿»è¯‘å®Œæˆ: {translated_text}")
        return translated_text
    except Exception as e:
        logger.error(f"ç¿»è¯‘é”™è¯¯: {e}")
        traceback.print_exc()
        return text  # è¿”å›åŸæ–‡æœ¬ä½œä¸ºfallback

def tts_synthesis_streaming(text, reference_audio=None, output_path=None):
    """
    ä½¿ç”¨é¢„åŠ è½½çš„TTSåˆæˆè¯­éŸ³å¹¶è¿”å›éŸ³é¢‘æµ
    """
    try:
        logger.info(f"ğŸµ ä½¿ç”¨TTSåˆæˆè¯­éŸ³æµ: {text}")
        
        # æ£€æŸ¥TTSæ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if preloaded_models['tts'] is None:
            logger.warning("TTSæ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")
            return None
        
        # ç¡®ä¿æœ‰æœ‰æ•ˆçš„å‚è€ƒéŸ³é¢‘
        if not reference_audio or not os.path.exists(reference_audio):
            if os.path.exists(default_ref_audio_path):
                logger.warning(f"âš ï¸ æœªæä¾›æœ‰æ•ˆå‚è€ƒéŸ³é¢‘ï¼Œä½¿ç”¨é»˜è®¤å‚è€ƒéŸ³é¢‘: {default_ref_audio_path}")
                reference_audio = default_ref_audio_path
            else:
                logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„å‚è€ƒéŸ³é¢‘")
                return None
        
        logger.info(f"ğŸ¯ ä½¿ç”¨å‚è€ƒéŸ³é¢‘: {os.path.basename(reference_audio)}")
        
        # ä½¿ç”¨é¢„åŠ è½½çš„TTSæ¨¡å‹
        tts = preloaded_models['tts']
        
        # ä½¿ç”¨æµå¼è¿”å›æ–¹å¼
        result = tts.infer(
            text=text,
            spk_audio_prompt=reference_audio,  # âœ… ç°åœ¨ä½¿ç”¨16kHzå‚è€ƒéŸ³é¢‘
            output_path=output_path,
            #stream_return=True,
            #verbose=True
        )
        
        logger.info("âœ… TTSæµå¼åˆæˆå¯åŠ¨æˆåŠŸ")
        return result  # è¿”å›ç”Ÿæˆå™¨å¯¹è±¡
    except Exception as e:
        logger.error(f"ğŸ’” TTSæµå¼åˆæˆé”™è¯¯: {e}")
        traceback.print_exc()
        
        # å°è¯•ä¸ä½¿ç”¨å‚è€ƒéŸ³é¢‘çš„fallback
        try:
            logger.info("ğŸ”„ å°è¯•ä¸ä½¿ç”¨å‚è€ƒéŸ³é¢‘...")
            tts = preloaded_models['tts']
            result = tts.infer(
                text=text,
                output_path=output_path,
                #stream_return=True,
                #verbose=True
            )
            logger.info("âœ… TTSå›é€€æ¨¡å¼åˆæˆæˆåŠŸ")
            return result
        except Exception as fallback_e:
            logger.error(f"ğŸ’” TTSå›é€€æ¨¡å¼ä¹Ÿå¤±è´¥: {fallback_e}")
            return None

@app.route('/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    loaded_models = [k for k, v in preloaded_models.items() if v is not None]
    return jsonify({
        "status": "healthy",
        "models_loaded": len(loaded_models),
        "loaded_models": loaded_models,
        "device": device,
        "default_ref_audio": os.path.exists(default_ref_audio_path)
    })

@app.route('/infer_wav', methods=['POST'])
def infer_wav():
    """
    ç®€åŒ–ç‰ˆï¼šè¿”å›å®Œæ•´çš„WAVæ–‡ä»¶
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ç¼ºå°‘JSONæ•°æ®"}), 400
        
        # æå–éŸ³é¢‘æ•°æ®
        audio_data_base64 = data.get("audio_data")
        if not audio_data_base64:
            return jsonify({"error": "ç¼ºå°‘audio_dataå‚æ•°"}), 400
        
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        audio_bytes = base64.b64decode(audio_data_base64)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio_bytes = np.nan_to_num(audio_bytes)
            f.write(audio_bytes)
            temp_audio_path = f.name
        
        try:
            # 1. é™å™ªå¤„ç†
            vocal_16k_path, ref_audio_16k_path = denoise_audio_hp2(temp_audio_path)
            if not vocal_16k_path or not ref_audio_16k_path:
                return jsonify({"error": "é™å™ªå¤„ç†å¤±è´¥"}), 500
            
            # 2. ASRè¯†åˆ«
            asr_language = data.get("asr_language", None)
            asr_result = asr_recognition(vocal_16k_path, asr_language)
            if not asr_result:
                return jsonify({"error": "ASRè¯†åˆ«å¤±è´¥"}), 500
            
            # 3. ç¿»è¯‘
            target_language = data.get("target_language", "zh")
            source_language = "ja" if asr_language == "ja" else "en"  # ç®€åŒ–
            translated_text = translate_text(asr_result, target_language, source_language)
            
            # 4. TTSåˆæˆ
            tts_output_path = os.path.join(RESULTS_DIR, "tts_output", f"tts_result_{int(time.time()*1000)}.wav")
            os.makedirs(os.path.dirname(tts_output_path), exist_ok=True)
            
            # åŒæ­¥TTSåˆæˆ
            if preloaded_models['tts']:
                tts = preloaded_models['tts']
                tts.infer(
                    text=translated_text,
                    spk_audio_prompt=ref_audio_16k_path,
                    output_path=tts_output_path
                )
            else:
                return jsonify({"error": "TTSæ¨¡å‹æœªåŠ è½½"}), 500
            
            # 5. è¯»å–WAVæ–‡ä»¶
            with open(tts_output_path, "rb") as f:
                wav_bytes = f.read()
            
            # 6. è½¬æ¢ä¸ºBase64
            wav_base64 = base64.b64encode(wav_bytes).decode('utf-8')
            
            return jsonify({
                "success": True,
                "text_original": asr_result,
                "text_translated": translated_text,
                "wav_data": wav_base64,
                "wav_size": len(wav_bytes)
            })
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for path in [temp_audio_path, vocal_16k_path, ref_audio_16k_path]:
                if path and os.path.exists(path):
                    try:
                        os.remove(path)
                    except:
                        pass
    
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    if not preload_models():
        logger.error("æ¨¡å‹é¢„åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(1)
    
    # å¯åŠ¨FlaskæœåŠ¡
    port = int(os.environ.get("PORT", 5000))
    logger.info(f"ğŸš€ å¯åŠ¨æ¨¡å‹æœåŠ¡ï¼Œç›‘å¬ç«¯å£: {port}")
    logger.info(f"âœ… æœåŠ¡å‡†å¤‡å°±ç»ªï¼è®¿é—® http://localhost:{port}/health æ£€æŸ¥çŠ¶æ€")
    app.run(host="0.0.0.0", port=port, debug=False)
